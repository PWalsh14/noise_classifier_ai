# ğŸ§  AI Sound Classifier Web App

A beginner-friendly web application that uses deep learning to classify environmental sounds through spectrogram analysis. Built for educational purposes, with an emphasis on transparency and explanation for non-experts.

---

## ğŸš€ Features

- ğŸ§ **Upload audio files** to get real-time sound predictions
- ğŸ“Š **Visualize waveforms and spectrograms** to understand audio data
- ğŸ¤– **AI-powered predictions** using a Convolutional Neural Network (CNN)
- ğŸ§ª **Try sample audio** to test without needing your own `.wav` file
- ğŸ§  **Learn AI concepts** via interactive, glossary-linked sections
- ğŸ’¬ **Chatbot assistant** to help users explore concepts further
- ğŸ§© **Gamified learning** with a Match-Pairs Quiz to reinforce key AI concepts
- ğŸ” **Confidence score** and guided interpretation of predictions
- ğŸ“š **Glossary with expandable terms** to aid understanding
- ğŸŒ— **Dark mode** support for improved accessibility

---

## ğŸ—ï¸ Project Structure

backend/ # Flask API backend app.py # Main server script model/ # Trained CNN model and label map audio_classifier.h5 label_map.txt

frontend/ # React frontend public/ samples/ # Sample audio files src/ components/ # Reusable components (e.g., Navbar, GlossaryTerm) pages/ # Main page views (Home, TryIt, Learn, etc.) data/ # Glossary definitions App.jsx # Main app entry point and routing

.gitignore README.md requirements.txt # Python dependencies (backend) package.json # React frontend dependencies prepare_esc10.py # Dataset preparation script

---

## ğŸ§  Technologies Used

- **Frontend:** React, TailwindCSS, Axios
- **Backend:** Flask, TensorFlow, Librosa
- **AI Model:** CNN trained on ESC-10 (subset of ESC-50 dataset)

---

## ğŸ“ How It Works

1. Audio is uploaded (or a sample is selected)
2. It's converted into a spectrogram (a visual image of sound over time)
3. A CNN analyses this spectrogram to classify the sound
4. The result is displayed along with visual explanations

---

## ğŸ§ª Try It Yourself

- Go to the **Try It** page
- Upload a `.wav` file (e.g., dog bark, rain, clock tick)
- View the **prediction**, **confidence score**, and **spectrogram visualization**
- You can also use **example audio samples** if you donâ€™t have a file

---

## ğŸ§  Model Info

The app is powered by a custom-built Convolutional Neural Network (CNN) trained on the ESC-10 dataset, which contains 10 categories of environmental sounds.

### ğŸ” Model Architecture

- Input: 128Ã—128Ã—3 mel spectrogram images
- Layers: Conv2D â†’ BatchNorm â†’ MaxPooling â†’ Conv2D â†’ BatchNorm â†’ MaxPooling â†’ Dense â†’ Output (Softmax)

### ğŸ§  Training Details

- Framework: TensorFlow/Keras
- Input pipeline: .wav audio â” mel spectrogram conversion (Librosa)
- 80/20 train-validation split
- Optimizer: Adam
- Loss: Sparse categorical crossentropy

### ğŸ“ˆ Performance

- Final validation accuracy: ~80%
- Strong performance on clean, in-distribution recordings
- Confidence scores included with predictions
- Potential misclassification for noisy or unfamiliar real-world audio

### âš ï¸ Known Limitations

- Only recognises ESC-10 sound categories
- Struggles with overlapping or noisy environments
- Overconfident outputs (common in softmax-based classifiers)

---

## ğŸ“š Based On

This project is inspired by concepts from Chapter 12 of *Practical Deep Learning for Coders* by Jeremy Howard and Sylvain Gugger.  
ğŸ”— [Read the chapter (PDF)](https://nostarch.com/download/PracticalDeepLearning2e_Chapter12.pdf)

---

## ğŸ™‹ Who's It For?

- Students learning AI and deep learning fundamentals
- Educators who want a live demonstration of how audio classification works
- Anyone curious about how machines "hear" and analyse sounds

---

## ğŸ§¼ Notes

- `.wav` format only (current version)
- Browser-based, no user login or data storage
- Static spectrogram previews; Grad-CAM or other live explainability tools are potential future upgrades

---

## ğŸ› ï¸ Future Improvements

- Expand training to ESC-50 and UrbanSound8K datasets
- Add support for real-time microphone input
- Implement more AI model explainability (live Grad-CAM overlays)
- Broader file format support (.mp3, .m4a, etc.)
- In-app tutorials and guided walkthroughs

---

## ğŸ‘¨â€ğŸ’» Author

**Patrick Walsh**  
Dissertation Project Â· Newcastle University  
GitHub: [@PWalsh14](https://github.com/PWalsh14)
